{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a455b36d-7c67-4faa-9f73-01ca0f5f5211",
   "metadata": {},
   "source": [
    "# CNN Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d64e13-308d-4cfb-9067-72eb3b4579db",
   "metadata": {},
   "source": [
    "**This notebook will build the following model**:\n",
    "- Use only 50% of the data? No\n",
    "- Batch Size: 32\n",
    "- Batch Normalization: Yes, after every convolution\n",
    "- Early Stopping: Yes, patience=3\n",
    "- Reduce Learning Rate: Yes, patience=1\n",
    "- Initial Learning Rate: 0.0001\n",
    "- Epochs (max): 15\n",
    "- Architecture:\n",
    "    - Feature Extractor: \\[Convolution -> Convolution -> Max Pool] repeated 5 times.\n",
    "        - Relu activation function throughout\n",
    "        - 2x2 pooling size\n",
    "        - 3x3 filter size throughout\n",
    "        - Filter count per convolution: 32, 64, 128, 256, 512\n",
    "    - Classifier: 1 dense layer with 256 units\n",
    "        - Sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24199120-84a0-4d78-be72-dfedec011ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline import (prep_data, get_train_val_test_data, create_tensorflow_datasets, predict_on_kaggle_test_set)\n",
    "from model_helper_functions import map_to_metrics, plot_metric, plot_learning_rate, save_history\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from time import time, gmtime\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee712581-30f3-4356-8ce5-34a2e48edf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a692d-b7b8-48bd-9d7f-eeb2499e71a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a48a4-3a3b-4164-8371-e721ece70826",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f8daa-73ca-4ffb-bd64-3f0bcc8fb326",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb7170-a7ac-44e1-a06c-da64598fea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "df, train_val_dir = prep_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58f10f-fe53-48bf-b93a-6bbc74deae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_train_val_test_data(df, use_half_data=False)\n",
    "train_ds_str, val_ds_str, test_ds_str, train_ds, val_ds, test_ds = create_tensorflow_datasets(train_df, val_df, test_df, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a3dcb-6098-401a-baf5-7e95ab71e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(train_val_dir.glob('*/*.tif')))\n",
    "print('Total image count:',image_count)\n",
    "print('Image count equal to dataframe length?', image_count == len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65476f3-6501-4999-a183-4daa23a86bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = tf.data.experimental.cardinality(train_ds_str).numpy()\n",
    "num_val_samples = tf.data.experimental.cardinality(val_ds_str).numpy()\n",
    "num_test_samples = tf.data.experimental.cardinality(test_ds_str).numpy()\n",
    "print('Number of training samples:',num_train_samples)\n",
    "print('Number of validation samples::',num_val_samples)\n",
    "print('Number of test samples:',num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6feaaf-6d28-4a01-b3cc-4b4ccb46b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = Image.open(df.loc[0, 'path'])\n",
    "image_shape = np.array(example_image).shape\n",
    "print('Image shape:', image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95931e-6e68-494c-8f42-acbf3c82b3c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767fe39-bbee-452c-80e5-246b99c6e15e",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ee9fa-fa34-49c5-bf59-61b39da9e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'model6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc5168-9ec1-482a-b891-30e8544d77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = OrderedDict([\n",
    "    ('accuracy', keras.metrics.BinaryAccuracy(name='accuracy')),\n",
    "    ('auc', keras.metrics.AUC(name='auc')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83f0a5-04f4-4738-9c0b-e926f9271991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = './model_checkpoints'\n",
    "checkpoint_path = f\"{model_output_dir}/{MODEL_NAME}/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35117611-282e-4e02-a63c-fd3fc4b0cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for early stopping and learning rate reduction\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "reducel = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427969d-6fef-473c-b5ec-b55320bcd1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Feature Extractor\n",
    "# N_1\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=image_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# N_2\n",
    "model.add(layers.Conv2D(64, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# N_3\n",
    "model.add(layers.Conv2D(128, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "# N_4\n",
    "model.add(layers.Conv2D(256, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# N_5\n",
    "model.add(layers.Conv2D(512, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "# Classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss = \"binary_crossentropy\",\n",
    "              metrics=list(model_metrics.values()))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0c362-8556-4475-8bea-309063d56867",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f1d89-cc9d-4909-a688-2163f3a96fdc",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd1b8d-d2ea-418f-ae88-da11d9e90cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29476272-690e-4fcd-ab0b-8e77ba1f6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[cp_callback, reducel, earlystopper]\n",
    "                   )\n",
    "total_time = time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff87ee7-420f-491e-80e7-0f63263bc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_time = gmtime(total_time)\n",
    "print(f'Total model fitting time: {conv_time.tm_hour} hours, {conv_time.tm_min} minutes, {conv_time.tm_sec} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35a136-d41a-4840-8311-bd7cdbb20a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "history_dict = save_history(history, total_time, model_output_dir, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ae799-e999-4a46-9b6e-82e93878bb3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34cae7-8059-4b0b-8121-ef3538ecb88e",
   "metadata": {},
   "source": [
    "## Plot Training and Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e43842-2e59-4a4c-8eb6-0a2bb253a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_rate(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af5f73-54bf-492b-b91a-2c0613728102",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history_dict, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f57d7-0eab-4dfa-b0da-f3e3f135b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history_dict, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebbdb7-c36f-4ced-bed9-68d0746c0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history_dict, 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29faf5d0-08a3-459c-8681-b8209201292e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742b879-e2e8-489a-a6f2-8048f5474097",
   "metadata": {},
   "source": [
    "## Calculate Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b3aa8-473d-46b9-86a0-d6b364edf455",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(test_ds, verbose=1)\n",
    "test_metrics = map_to_metrics(model.metrics_names, test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162a286-baf8-44e7-b1b8-04ac16e5caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test metrics\n",
    "json.dump(test_metrics, open(f\"{model_output_dir}/{MODEL_NAME}/test_metrics.json\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11941c8-3388-477e-ba8a-275aad654265",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
